{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('treebank')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import random\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "import base64\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.max_length = 16000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['were',\n",
       " 'moreover',\n",
       " 'did',\n",
       " 'one',\n",
       " 'upon',\n",
       " 'yours',\n",
       " 'latterly',\n",
       " 'ever',\n",
       " 'me',\n",
       " 'used',\n",
       " \"'m\",\n",
       " 'could',\n",
       " 'nothing',\n",
       " 'they',\n",
       " 'whenever',\n",
       " 'show',\n",
       " '‘d',\n",
       " 'here',\n",
       " 'in',\n",
       " 'take',\n",
       " 'next',\n",
       " 'quite',\n",
       " 'seem',\n",
       " 'herself',\n",
       " 'whereas',\n",
       " 'over',\n",
       " 'anyhow',\n",
       " 'them',\n",
       " 'always',\n",
       " 'if',\n",
       " 'put',\n",
       " 'are',\n",
       " 'was',\n",
       " 'everything',\n",
       " 'becomes',\n",
       " 'twelve',\n",
       " 'also',\n",
       " 'up',\n",
       " 'name',\n",
       " 'formerly',\n",
       " 'her',\n",
       " 'three',\n",
       " '’re',\n",
       " 'mostly',\n",
       " 'myself',\n",
       " 'nevertheless',\n",
       " \"'re\",\n",
       " 'as',\n",
       " 'whence',\n",
       " '‘re',\n",
       " 'than',\n",
       " 'noone',\n",
       " 'often',\n",
       " 'first',\n",
       " 'through',\n",
       " 'enough',\n",
       " 'yourself',\n",
       " 'nobody',\n",
       " 'although',\n",
       " '’s',\n",
       " 'is',\n",
       " 'while',\n",
       " 'whoever',\n",
       " 'all',\n",
       " 'to',\n",
       " 'had',\n",
       " 'my',\n",
       " 'beyond',\n",
       " 'such',\n",
       " 'herein',\n",
       " 'together',\n",
       " 'who',\n",
       " 'see',\n",
       " 'after',\n",
       " 'anyone',\n",
       " 'move',\n",
       " 'meanwhile',\n",
       " 'now',\n",
       " 'just',\n",
       " 'whereafter',\n",
       " 'there',\n",
       " 'thus',\n",
       " 'whereby',\n",
       " 'almost',\n",
       " 'back',\n",
       " 'done',\n",
       " 'when',\n",
       " 'really',\n",
       " 'no',\n",
       " 'anywhere',\n",
       " 'between',\n",
       " 'four',\n",
       " 'until',\n",
       " 'eight',\n",
       " 'on',\n",
       " 'rather',\n",
       " 'namely',\n",
       " 'hereupon',\n",
       " 'hereby',\n",
       " 'yet',\n",
       " 'mine',\n",
       " 'sometime',\n",
       " 'should',\n",
       " 'above',\n",
       " 'cannot',\n",
       " 'per',\n",
       " 'eleven',\n",
       " 'doing',\n",
       " 'others',\n",
       " 'has',\n",
       " 'its',\n",
       " 'the',\n",
       " 'once',\n",
       " 'somewhere',\n",
       " '‘ll',\n",
       " 'very',\n",
       " 'go',\n",
       " 'what',\n",
       " 'ours',\n",
       " \"'ll\",\n",
       " 'beforehand',\n",
       " 'much',\n",
       " 'am',\n",
       " 'toward',\n",
       " 'former',\n",
       " 'whether',\n",
       " 're',\n",
       " 'fifty',\n",
       " 'call',\n",
       " 'since',\n",
       " 'seeming',\n",
       " 'please',\n",
       " 'therefore',\n",
       " 'under',\n",
       " 'latter',\n",
       " 'with',\n",
       " 'two',\n",
       " 'wherein',\n",
       " 'among',\n",
       " 'keep',\n",
       " 'below',\n",
       " 'ourselves',\n",
       " 'except',\n",
       " 'twenty',\n",
       " 'whereupon',\n",
       " 'amongst',\n",
       " 'someone',\n",
       " 'thru',\n",
       " 'their',\n",
       " 'made',\n",
       " 'bottom',\n",
       " 'regarding',\n",
       " 'ten',\n",
       " 'serious',\n",
       " 'only',\n",
       " 'already',\n",
       " 'perhaps',\n",
       " 'you',\n",
       " \"'d\",\n",
       " 'most',\n",
       " 'wherever',\n",
       " 'during',\n",
       " 'front',\n",
       " 'his',\n",
       " 'whatever',\n",
       " 'become',\n",
       " 'seemed',\n",
       " 'full',\n",
       " 'i',\n",
       " 'became',\n",
       " 'been',\n",
       " 'into',\n",
       " 'give',\n",
       " 'why',\n",
       " 'have',\n",
       " 'several',\n",
       " 'these',\n",
       " 'neither',\n",
       " 'thereby',\n",
       " 'becoming',\n",
       " 'get',\n",
       " 'it',\n",
       " 'besides',\n",
       " 'hers',\n",
       " 'never',\n",
       " 'well',\n",
       " 'then',\n",
       " 'would',\n",
       " 'n’t',\n",
       " 'us',\n",
       " 'an',\n",
       " 'forty',\n",
       " 'off',\n",
       " 'being',\n",
       " 'still',\n",
       " 'everywhere',\n",
       " 'nowhere',\n",
       " 'against',\n",
       " 'thereafter',\n",
       " 'indeed',\n",
       " 'various',\n",
       " 'many',\n",
       " 'along',\n",
       " 'afterwards',\n",
       " 'our',\n",
       " '’ll',\n",
       " 'top',\n",
       " 'anything',\n",
       " 'he',\n",
       " '’m',\n",
       " 'might',\n",
       " 'five',\n",
       " '‘ve',\n",
       " 'a',\n",
       " \"'s\",\n",
       " 'same',\n",
       " 'further',\n",
       " 'where',\n",
       " 'whom',\n",
       " 'we',\n",
       " 'say',\n",
       " 'must',\n",
       " 'from',\n",
       " 'nine',\n",
       " 'last',\n",
       " 'will',\n",
       " 'another',\n",
       " 'even',\n",
       " 'via',\n",
       " 'beside',\n",
       " 'and',\n",
       " 'alone',\n",
       " 'of',\n",
       " 'few',\n",
       " 'too',\n",
       " '‘m',\n",
       " 'or',\n",
       " 'side',\n",
       " 'though',\n",
       " 'before',\n",
       " 'everyone',\n",
       " 'anyway',\n",
       " 'sometimes',\n",
       " 'those',\n",
       " 'do',\n",
       " 'nor',\n",
       " 'within',\n",
       " 'does',\n",
       " 'itself',\n",
       " '‘s',\n",
       " 'least',\n",
       " 'thence',\n",
       " 'down',\n",
       " \"n't\",\n",
       " 'himself',\n",
       " 'ca',\n",
       " 'whither',\n",
       " 'be',\n",
       " 'due',\n",
       " 'without',\n",
       " 'own',\n",
       " 'but',\n",
       " 'yourselves',\n",
       " 'part',\n",
       " 'themselves',\n",
       " 'how',\n",
       " 'empty',\n",
       " 'using',\n",
       " 'by',\n",
       " 'throughout',\n",
       " 'not',\n",
       " 'at',\n",
       " 'hundred',\n",
       " 'less',\n",
       " 'around',\n",
       " 'which',\n",
       " 'towards',\n",
       " '’ve',\n",
       " 'thereupon',\n",
       " 'because',\n",
       " 'onto',\n",
       " 'therein',\n",
       " 'hereafter',\n",
       " 'else',\n",
       " 'for',\n",
       " 'six',\n",
       " 'elsewhere',\n",
       " 'every',\n",
       " 'behind',\n",
       " 'him',\n",
       " 'hence',\n",
       " 'otherwise',\n",
       " 'out',\n",
       " 'something',\n",
       " 'amount',\n",
       " 'fifteen',\n",
       " \"'ve\",\n",
       " 'so',\n",
       " 'about',\n",
       " 'either',\n",
       " 'seems',\n",
       " 'your',\n",
       " 'she',\n",
       " '’d',\n",
       " 'more',\n",
       " 'can',\n",
       " 'unless',\n",
       " 'any',\n",
       " 'that',\n",
       " 'n‘t',\n",
       " 'whose',\n",
       " 'none',\n",
       " 'may',\n",
       " 'however',\n",
       " 'make',\n",
       " 'sixty',\n",
       " 'again',\n",
       " 'somehow',\n",
       " 'some',\n",
       " 'third',\n",
       " 'each',\n",
       " 'across',\n",
       " 'whole',\n",
       " 'this',\n",
       " 'other',\n",
       " 'both']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>ReviewUpdated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>TitleGoodBad</th>\n",
       "      <th>ProductPrice</th>\n",
       "      <th>ProductPriceRange</th>\n",
       "      <th>Year</th>\n",
       "      <th>positive_negative</th>\n",
       "      <th>...</th>\n",
       "      <th>Positive_Negative_Tag</th>\n",
       "      <th>LengthofReviews</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>SentimentSubjectivity</th>\n",
       "      <th>SentimentPolarityClass</th>\n",
       "      <th>AvgSentPolarity</th>\n",
       "      <th>AvgSentimentPolarityClass</th>\n",
       "      <th>AvgSentimentSubjectivity</th>\n",
       "      <th>ReviewUpdated1</th>\n",
       "      <th>ReviewUpdated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['yet', 'another', 'value', 'money', 'product'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jul 17, 2016 10:59 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Yet another Value for Money product from Xiaomi</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>344</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>Negative Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yet another Value for Money product from Xiaom...</td>\n",
       "      <td>Yet another Value for Money product from Xiaom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['awesome', 'marvelous', 'mobile', 'go', 'valu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 10:42 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>276</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome  Marvelous Mobile just go for it., Val...</td>\n",
       "      <td>Awesome  Marvelous Mobile just go for it., Val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['power', 'pack', 'review', 'redmi', 'note', '...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 06:18 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Power pack review on Redmi Note 3</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>322</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.477037</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power pack review on Redmi Note 3  REDMI NOTE ...</td>\n",
       "      <td>Power pack review on Redmi Note 3  REDMI NOTE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['flagship', 'smartfone', 'phone', 'looks', 'v...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jul 17, 2016 04:44 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Flagship smartfone under 13000rs</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>333</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flagship smartfone under 13000rs  This phone l...</td>\n",
       "      <td>Flagship smartfone under 13000rs  This phone l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['boon', 'mobile', 'master', 'piece', 'economi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 12:32 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Boon for mobile</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>316</td>\n",
       "      <td>0.448571</td>\n",
       "      <td>0.627857</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boon for mobile  Master piece in such a econom...</td>\n",
       "      <td>Boon for mobile  Master piece in such a econom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Product                                      ReviewUpdated  \\\n",
       "0  Xiaomi Redmi Note 3  ['yet', 'another', 'value', 'money', 'product'...   \n",
       "1  Xiaomi Redmi Note 3  ['awesome', 'marvelous', 'mobile', 'go', 'valu...   \n",
       "2  Xiaomi Redmi Note 3  ['power', 'pack', 'review', 'redmi', 'note', '...   \n",
       "3  Xiaomi Redmi Note 3  ['flagship', 'smartfone', 'phone', 'looks', 'v...   \n",
       "4  Xiaomi Redmi Note 3  ['boon', 'mobile', 'master', 'piece', 'economi...   \n",
       "\n",
       "   Rating                   Date    Website  \\\n",
       "0     3.0  Jul 17, 2016 10:59 PM  MouthShut   \n",
       "1     5.0  Jul 17, 2016 10:42 PM  MouthShut   \n",
       "2     5.0  Jul 17, 2016 06:18 PM  MouthShut   \n",
       "3     4.0  Jul 17, 2016 04:44 PM  MouthShut   \n",
       "4     5.0  Jul 17, 2016 12:32 PM  MouthShut   \n",
       "\n",
       "                                        TitleGoodBad ProductPrice  \\\n",
       "0  Yet another Value for Money product from Xiaomi           9999   \n",
       "1                                          Awesome           9999   \n",
       "2                Power pack review on Redmi Note 3           9999   \n",
       "3                 Flagship smartfone under 13000rs           9999   \n",
       "4                                  Boon for mobile           9999   \n",
       "\n",
       "  ProductPriceRange    Year  positive_negative  ...  Positive_Negative_Tag  \\\n",
       "0      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "1      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "2      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "3      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "4      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "\n",
       "   LengthofReviews SentimentPolarity SentimentSubjectivity  \\\n",
       "0              344         -0.028571              0.576190   \n",
       "1              276          0.780000              0.640000   \n",
       "2              322          0.474444              0.477037   \n",
       "3              333          0.502500              0.832500   \n",
       "4              316          0.448571              0.627857   \n",
       "\n",
       "   SentimentPolarityClass  AvgSentPolarity  AvgSentimentPolarityClass  \\\n",
       "0         Negative Rating         0.403533            Positive Rating   \n",
       "1         Positive Rating         0.403533            Positive Rating   \n",
       "2         Positive Rating         0.403533            Positive Rating   \n",
       "3         Positive Rating         0.403533            Positive Rating   \n",
       "4         Positive Rating         0.403533            Positive Rating   \n",
       "\n",
       "  AvgSentimentSubjectivity                                     ReviewUpdated1  \\\n",
       "0                      NaN  Yet another Value for Money product from Xiaom...   \n",
       "1                      NaN  Awesome  Marvelous Mobile just go for it., Val...   \n",
       "2                      NaN  Power pack review on Redmi Note 3  REDMI NOTE ...   \n",
       "3                      NaN  Flagship smartfone under 13000rs  This phone l...   \n",
       "4                      NaN  Boon for mobile  Master piece in such a econom...   \n",
       "\n",
       "                                      ReviewUpdated2  \n",
       "0  Yet another Value for Money product from Xiaom...  \n",
       "1  Awesome  Marvelous Mobile just go for it., Val...  \n",
       "2  Power pack review on Redmi Note 3  REDMI NOTE ...  \n",
       "3  Flagship smartfone under 13000rs  This phone l...  \n",
       "4  Boon for mobile  Master piece in such a econom...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatestMobileReviews1 = pd.read_csv('C:\\\\Users\\\\halapets\\\\Documents\\\\LJMU Research_Sentiment Analysis\\\\LatestMobileReviews.csv',encoding='latin1')\n",
    "LatestMobileReviews1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160057, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatestMobileReviews1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization and text preprocessing\n",
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\" or token.pos_ != \"AUX\" or token.pos_ != \"NUM\" or token.pos_ != \"SYM\" or token.pos_ != \"ADP\"  :\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        tokens.append(temp)\n",
    "        \n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in punct and token.isalpha():\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'like', 'video', 'advise']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaning(\"    Hello how are you. Like this video! Please advise $\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word vectorization using tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = LatestMobileReviews1['ReviewUpdated1']\n",
    "y= LatestMobileReviews1 ['positive_negative']\n",
    "len(X)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160057, 101644)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160057,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting TFIDF Matrix to dataframe\n",
    "#df_TFIDF = pd.DataFrame(X_transformed.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_TFIDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing dataframe \n",
    "#df_TFIDF.to_csv(\"df_TFIDF.csv\",index =False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model on TFIDF Vectorization (Classifiers used- Decision Tree, Naive Bayes, Decision Tree and Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "model4 = BernoulliNB()\n",
    "estimators.append(('NB', model4))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9034468286080192\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(ensemble, X_transformed, y, cv=kfold)\n",
    "print(results.mean())#mean estimate of classification accuracy 0.9034468286080192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009175947317369745"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std()# Standard Deviation for classification accuracy 0.009175947317369745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###------------------------------------------------------####--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word vectorization using tfidf\n",
    "BOW = CountVectorizer(tokenizer = text_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160057"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = LatestMobileReviews1['ReviewUpdated']\n",
    "y= LatestMobileReviews1 ['positive_negative']\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed_BOW = BOW.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160057, 156147)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed_BOW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160057,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting TFIDF Matrix to dataframe\n",
    "#df_BOW = pd.DataFrame(X_transformed_BOW.toarray(), columns=BOW.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_BOW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model on Count Vectorization-Bag of Words (Classifiers used- Decision Tree, Naive Bayes, Decision Tree and Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "model4 = BernoulliNB()\n",
    "estimators.append(('NB', model4))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035717859272561\n"
     ]
    }
   ],
   "source": [
    "results_BOW = model_selection.cross_val_score(ensemble, X_transformed_BOW, y, cv=kfold)\n",
    "print(results_BOW.mean()) #mean estimate of classification accuracy 0.9035717859272561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008914551654112519"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_BOW.std()# Standard Deviation for classification accuracy 0.008914551654112519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
