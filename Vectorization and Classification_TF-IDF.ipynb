{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\halapets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('treebank')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import random\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "import base64\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.max_length = 16000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount',\n",
       " 'two',\n",
       " 'nobody',\n",
       " 'him',\n",
       " 'below',\n",
       " 'ca',\n",
       " 'under',\n",
       " 'about',\n",
       " 'we',\n",
       " '’s',\n",
       " 'on',\n",
       " 'they',\n",
       " 'ten',\n",
       " 'what',\n",
       " 'had',\n",
       " 'most',\n",
       " 'too',\n",
       " 'empty',\n",
       " 'here',\n",
       " 'another',\n",
       " 'side',\n",
       " 'own',\n",
       " '’ve',\n",
       " 'same',\n",
       " 'then',\n",
       " '‘ll',\n",
       " 'so',\n",
       " 'am',\n",
       " 'thus',\n",
       " 'since',\n",
       " 'seeming',\n",
       " 'twelve',\n",
       " 'and',\n",
       " 'take',\n",
       " 'therefore',\n",
       " 'per',\n",
       " 'n‘t',\n",
       " 'cannot',\n",
       " 'only',\n",
       " 'call',\n",
       " 'regarding',\n",
       " 'should',\n",
       " 'but',\n",
       " 'besides',\n",
       " 'made',\n",
       " 'were',\n",
       " 'sometimes',\n",
       " 'n’t',\n",
       " 'while',\n",
       " '‘s',\n",
       " 'over',\n",
       " 'its',\n",
       " 'hereby',\n",
       " 'would',\n",
       " 'hers',\n",
       " 'just',\n",
       " 'throughout',\n",
       " 'will',\n",
       " 'move',\n",
       " 'anyone',\n",
       " 'onto',\n",
       " 'anything',\n",
       " 'do',\n",
       " 'something',\n",
       " 'yourself',\n",
       " 'behind',\n",
       " 'rather',\n",
       " 'everything',\n",
       " 'along',\n",
       " 'whatever',\n",
       " 'one',\n",
       " 'seem',\n",
       " 'see',\n",
       " 'except',\n",
       " 'else',\n",
       " 'latterly',\n",
       " 'bottom',\n",
       " 'the',\n",
       " 'when',\n",
       " 'as',\n",
       " 'up',\n",
       " 'get',\n",
       " 'top',\n",
       " \"'re\",\n",
       " \"'ve\",\n",
       " 'that',\n",
       " 'among',\n",
       " 'few',\n",
       " 'our',\n",
       " 'now',\n",
       " 'toward',\n",
       " 'some',\n",
       " 'formerly',\n",
       " 'latter',\n",
       " 'nowhere',\n",
       " 'may',\n",
       " 'whereby',\n",
       " 'used',\n",
       " 'these',\n",
       " 'less',\n",
       " 'more',\n",
       " \"'d\",\n",
       " 'at',\n",
       " 'third',\n",
       " 'those',\n",
       " 'last',\n",
       " 'eleven',\n",
       " 'several',\n",
       " 'becoming',\n",
       " 'none',\n",
       " \"'ll\",\n",
       " 'therein',\n",
       " 'myself',\n",
       " 'keep',\n",
       " 'beside',\n",
       " 'for',\n",
       " 'there',\n",
       " 'forty',\n",
       " 'who',\n",
       " 'of',\n",
       " 'part',\n",
       " 'has',\n",
       " 'with',\n",
       " 'various',\n",
       " 'unless',\n",
       " 'anyway',\n",
       " 'becomes',\n",
       " 'might',\n",
       " 'five',\n",
       " 'three',\n",
       " 'somehow',\n",
       " 'whether',\n",
       " 'thru',\n",
       " 'whole',\n",
       " 'to',\n",
       " 'namely',\n",
       " 'across',\n",
       " 'must',\n",
       " 'seemed',\n",
       " 'further',\n",
       " 'often',\n",
       " 'himself',\n",
       " 'well',\n",
       " 'six',\n",
       " 'also',\n",
       " 'nothing',\n",
       " 'in',\n",
       " 'hereupon',\n",
       " 'can',\n",
       " 'you',\n",
       " 'thereby',\n",
       " 'whenever',\n",
       " 'a',\n",
       " 'herein',\n",
       " 'not',\n",
       " 'both',\n",
       " 'during',\n",
       " 'go',\n",
       " 'back',\n",
       " 'former',\n",
       " 'show',\n",
       " 'everywhere',\n",
       " 'wherever',\n",
       " 'sometime',\n",
       " 'any',\n",
       " 'between',\n",
       " 'been',\n",
       " 'beforehand',\n",
       " 'upon',\n",
       " 'how',\n",
       " 'quite',\n",
       " 'did',\n",
       " 'if',\n",
       " 'off',\n",
       " 'where',\n",
       " 'thereupon',\n",
       " '’ll',\n",
       " 'least',\n",
       " 'still',\n",
       " 'ourselves',\n",
       " 'yours',\n",
       " 'his',\n",
       " 'twenty',\n",
       " 'again',\n",
       " 'thereafter',\n",
       " 'ours',\n",
       " 'her',\n",
       " 'an',\n",
       " '’re',\n",
       " 'before',\n",
       " '’m',\n",
       " 'either',\n",
       " 'us',\n",
       " 'fifty',\n",
       " 'afterwards',\n",
       " 'thence',\n",
       " 'all',\n",
       " 'always',\n",
       " 'each',\n",
       " 'which',\n",
       " 'or',\n",
       " 'within',\n",
       " 'hereafter',\n",
       " 'out',\n",
       " 'their',\n",
       " 'four',\n",
       " 'already',\n",
       " 'such',\n",
       " '‘m',\n",
       " 'because',\n",
       " 'even',\n",
       " 'me',\n",
       " 'much',\n",
       " 'yet',\n",
       " 'hundred',\n",
       " 'using',\n",
       " 'once',\n",
       " 'no',\n",
       " 'down',\n",
       " 'really',\n",
       " 'give',\n",
       " 'themselves',\n",
       " 'serious',\n",
       " 'say',\n",
       " 'whoever',\n",
       " 'together',\n",
       " 'anyhow',\n",
       " 'nevertheless',\n",
       " 'indeed',\n",
       " 'although',\n",
       " 'until',\n",
       " 'this',\n",
       " 'towards',\n",
       " '‘d',\n",
       " 'other',\n",
       " 'was',\n",
       " 'never',\n",
       " 'does',\n",
       " 'being',\n",
       " 'others',\n",
       " \"'m\",\n",
       " 'very',\n",
       " 'perhaps',\n",
       " 'become',\n",
       " 'is',\n",
       " 'moreover',\n",
       " 'without',\n",
       " 'after',\n",
       " 'i',\n",
       " 'whereupon',\n",
       " 'next',\n",
       " '’d',\n",
       " '‘re',\n",
       " 'sixty',\n",
       " 'whereafter',\n",
       " 'many',\n",
       " 'he',\n",
       " 'nine',\n",
       " 'whereas',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'whose',\n",
       " 'first',\n",
       " 'became',\n",
       " 'due',\n",
       " 'name',\n",
       " 'hence',\n",
       " 'could',\n",
       " 'into',\n",
       " 'why',\n",
       " 'eight',\n",
       " 'make',\n",
       " 'beyond',\n",
       " 'be',\n",
       " 'nor',\n",
       " 'put',\n",
       " 'whence',\n",
       " 'them',\n",
       " 'meanwhile',\n",
       " 'almost',\n",
       " \"n't\",\n",
       " 'from',\n",
       " 'front',\n",
       " 'please',\n",
       " 'full',\n",
       " 'someone',\n",
       " 'alone',\n",
       " 'than',\n",
       " 'otherwise',\n",
       " 'whom',\n",
       " 'seems',\n",
       " 'amongst',\n",
       " 'enough',\n",
       " 're',\n",
       " 'herself',\n",
       " 'my',\n",
       " 'though',\n",
       " 'have',\n",
       " 'every',\n",
       " 'anywhere',\n",
       " 'whither',\n",
       " 'it',\n",
       " 'by',\n",
       " 'through',\n",
       " 'she',\n",
       " 'via',\n",
       " 'itself',\n",
       " 'however',\n",
       " 'your',\n",
       " 'neither',\n",
       " 'noone',\n",
       " 'mine',\n",
       " '‘ve',\n",
       " 'mostly',\n",
       " 'against',\n",
       " 'around',\n",
       " 'elsewhere',\n",
       " 'above',\n",
       " 'wherein',\n",
       " 'everyone',\n",
       " \"'s\",\n",
       " 'ever',\n",
       " 'fifteen',\n",
       " 'are',\n",
       " 'yourselves',\n",
       " 'somewhere']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>ReviewUpdated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>TitleGoodBad</th>\n",
       "      <th>ProductPrice</th>\n",
       "      <th>ProductPriceRange</th>\n",
       "      <th>Year</th>\n",
       "      <th>positive_negative</th>\n",
       "      <th>...</th>\n",
       "      <th>Positive_Negative_Tag</th>\n",
       "      <th>LengthofReviews</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>SentimentSubjectivity</th>\n",
       "      <th>SentimentPolarityClass</th>\n",
       "      <th>AvgSentPolarity</th>\n",
       "      <th>AvgSentimentPolarityClass</th>\n",
       "      <th>AvgSentimentSubjectivity</th>\n",
       "      <th>ReviewUpdated1</th>\n",
       "      <th>ReviewUpdated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['yet', 'another', 'value', 'money', 'product'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jul 17, 2016 10:59 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Yet another Value for Money product from Xiaomi</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>344</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>Negative Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yet another Value for Money product from Xiaom...</td>\n",
       "      <td>Yet another Value for Money product from Xiaom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['awesome', 'marvelous', 'mobile', 'go', 'valu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 10:42 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>276</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome  Marvelous Mobile just go for it., Val...</td>\n",
       "      <td>Awesome  Marvelous Mobile just go for it., Val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['power', 'pack', 'review', 'redmi', 'note', '...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 06:18 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Power pack review on Redmi Note 3</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>322</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.477037</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power pack review on Redmi Note 3  REDMI NOTE ...</td>\n",
       "      <td>Power pack review on Redmi Note 3  REDMI NOTE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['flagship', 'smartfone', 'phone', 'looks', 'v...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jul 17, 2016 04:44 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Flagship smartfone under 13000rs</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>333</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flagship smartfone under 13000rs  This phone l...</td>\n",
       "      <td>Flagship smartfone under 13000rs  This phone l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>['boon', 'mobile', 'master', 'piece', 'economi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jul 17, 2016 12:32 PM</td>\n",
       "      <td>MouthShut</td>\n",
       "      <td>Boon for mobile</td>\n",
       "      <td>9999</td>\n",
       "      <td>Budget Range</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>316</td>\n",
       "      <td>0.448571</td>\n",
       "      <td>0.627857</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>Positive Rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boon for mobile  Master piece in such a econom...</td>\n",
       "      <td>Boon for mobile  Master piece in such a econom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Product                                      ReviewUpdated  \\\n",
       "0  Xiaomi Redmi Note 3  ['yet', 'another', 'value', 'money', 'product'...   \n",
       "1  Xiaomi Redmi Note 3  ['awesome', 'marvelous', 'mobile', 'go', 'valu...   \n",
       "2  Xiaomi Redmi Note 3  ['power', 'pack', 'review', 'redmi', 'note', '...   \n",
       "3  Xiaomi Redmi Note 3  ['flagship', 'smartfone', 'phone', 'looks', 'v...   \n",
       "4  Xiaomi Redmi Note 3  ['boon', 'mobile', 'master', 'piece', 'economi...   \n",
       "\n",
       "   Rating                   Date    Website  \\\n",
       "0     3.0  Jul 17, 2016 10:59 PM  MouthShut   \n",
       "1     5.0  Jul 17, 2016 10:42 PM  MouthShut   \n",
       "2     5.0  Jul 17, 2016 06:18 PM  MouthShut   \n",
       "3     4.0  Jul 17, 2016 04:44 PM  MouthShut   \n",
       "4     5.0  Jul 17, 2016 12:32 PM  MouthShut   \n",
       "\n",
       "                                        TitleGoodBad ProductPrice  \\\n",
       "0  Yet another Value for Money product from Xiaomi           9999   \n",
       "1                                          Awesome           9999   \n",
       "2                Power pack review on Redmi Note 3           9999   \n",
       "3                 Flagship smartfone under 13000rs           9999   \n",
       "4                                  Boon for mobile           9999   \n",
       "\n",
       "  ProductPriceRange    Year  positive_negative  ...  Positive_Negative_Tag  \\\n",
       "0      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "1      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "2      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "3      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "4      Budget Range  2016.0                  1  ...        Positive Rating   \n",
       "\n",
       "   LengthofReviews SentimentPolarity SentimentSubjectivity  \\\n",
       "0              344         -0.028571              0.576190   \n",
       "1              276          0.780000              0.640000   \n",
       "2              322          0.474444              0.477037   \n",
       "3              333          0.502500              0.832500   \n",
       "4              316          0.448571              0.627857   \n",
       "\n",
       "   SentimentPolarityClass  AvgSentPolarity  AvgSentimentPolarityClass  \\\n",
       "0         Negative Rating         0.403533            Positive Rating   \n",
       "1         Positive Rating         0.403533            Positive Rating   \n",
       "2         Positive Rating         0.403533            Positive Rating   \n",
       "3         Positive Rating         0.403533            Positive Rating   \n",
       "4         Positive Rating         0.403533            Positive Rating   \n",
       "\n",
       "  AvgSentimentSubjectivity                                     ReviewUpdated1  \\\n",
       "0                      NaN  Yet another Value for Money product from Xiaom...   \n",
       "1                      NaN  Awesome  Marvelous Mobile just go for it., Val...   \n",
       "2                      NaN  Power pack review on Redmi Note 3  REDMI NOTE ...   \n",
       "3                      NaN  Flagship smartfone under 13000rs  This phone l...   \n",
       "4                      NaN  Boon for mobile  Master piece in such a econom...   \n",
       "\n",
       "                                      ReviewUpdated2  \n",
       "0  Yet another Value for Money product from Xiaom...  \n",
       "1  Awesome  Marvelous Mobile just go for it., Val...  \n",
       "2  Power pack review on Redmi Note 3  REDMI NOTE ...  \n",
       "3  Flagship smartfone under 13000rs  This phone l...  \n",
       "4  Boon for mobile  Master piece in such a econom...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatestMobileReviews1 = pd.read_csv('C:\\\\Users\\\\halapets\\\\Documents\\\\LJMU Research_Sentiment Analysis\\\\LatestMobileReviews.csv',encoding='latin1')\n",
    "LatestMobileReviews1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization and text preprocessing\n",
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\" or token.pos_ != \"AUX\" or token.pos_ != \"NUM\" or token.pos_ != \"SYM\" or token.pos_ != \"ADP\"  :\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        tokens.append(temp)\n",
    "        \n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in punct and token.isalpha():\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product', 'ReviewUpdated', 'Rating', 'Date', 'Website', 'TitleGoodBad',\n",
       "       'ProductPrice', 'ProductPriceRange', 'Year', 'positive_negative',\n",
       "       'CountofReviews', 'AvgRating', 'AvgRatingScore',\n",
       "       'Positive_Negative_Tag', 'LengthofReviews', 'SentimentPolarity',\n",
       "       'SentimentSubjectivity', 'SentimentPolarityClass', 'AvgSentPolarity',\n",
       "       'AvgSentimentPolarityClass', 'AvgSentimentSubjectivity',\n",
       "       'ReviewUpdated1', 'ReviewUpdated2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaning(\"    Hello how are you. Like this video! Please advise $\")\n",
    "LatestMobileReviews1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization and LinearSVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC#change\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word vectorization using tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)####change\n",
    "#create base classifier\n",
    "classifier = LinearSVC()###change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = LatestMobileReviews1[['Product','ReviewUpdated1']]\n",
    "y= LatestMobileReviews1['positive_negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112039, 2), (112039,), (48018, 2), (48018,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline of steps to be followed for classifier\n",
    "clf_TFIDF_SVM = Pipeline([('tfidf', tfidf), ('clf', classifier)])#change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function text_data_cleaning at 0x0000017D927C8C18>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting model\n",
    "clf_TFIDF_SVM.fit(X_train['ReviewUpdated1'], y_train,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model on test data\n",
    "y_pred_TFIDF_SVM = clf_TFIDF_SVM.predict(X_test['ReviewUpdated1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.77      0.57      0.66      7791\\n     class 1       0.92      0.97      0.94     40227\\n\\n    accuracy                           0.90     48018\\n   macro avg       0.85      0.77      0.80     48018\\nweighted avg       0.90      0.90      0.90     48018\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "ClassificationReport_TFIDF_SVM=classification_report(y_test, y_pred_TFIDF_SVM, target_names=target_names)\n",
    "ClassificationReport_TFIDF_SVM\n",
    "\n",
    "#'              precision    recall  f1-score   support\\n\\n     \n",
    "#class 0       0.77      0.57      0.66      7791\\n     \n",
    "#class 1       0.92      0.97      0.94     40227\\n\\n    \n",
    "#accuracy                          0.90     48018\\n   \n",
    "#macro avg     0.85      0.77      0.80     48018\\n\n",
    "#weighted avg  0.90      0.90      0.90     48018\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4441,  3350],\n",
       "       [ 1293, 38934]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix_TFIDF_SVM=confusion_matrix(y_test, y_pred_TFIDF_SVM)\n",
    "ConfusionMatrix_TFIDF_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033070931733933"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TFIDF_SVM) \n",
    "#Accuracy-0.9033070931733933\n",
    "#Precision-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_SVM = pd.DataFrame(y_pred_TFIDF_SVM,X_test['Product'])\n",
    "y_pred_TFIDF_SVM.rename(columns={0:\"Tags_TFIDF_SVM\"}, inplace = True)\n",
    "y_pred_TFIDF_SVM.head(5)\n",
    "#len(y_pred_TFIDF_SVM)\n",
    "y_pred_TFIDF_SVM.to_csv(\"y_pred_TFIDF_SVM.csv\",header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "#param_grid = {'C': [0.1, 1, 10, 100, 1000]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "#grid_search = GridSearchCV(classifier, param_grid,cv = 3, verbose = 1,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "#grid_search.fit(tfidf.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_grid = grid_search.best_estimator_\n",
    "#best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_grid_search = grid_search.predict(tfidf.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.80      0.65      0.72     16505\\n     class 1       0.91      0.96      0.93     61332\\n\\n    accuracy                           0.89     77837\\n   macro avg       0.85      0.80      0.82     77837\\nweighted avg       0.89      0.89      0.89     77837\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target_names = ['class 0', 'class 1']\n",
    "#classification_report_SVM_gridsearch=classification_report(y_test, y_pred_grid_search, target_names=target_names)\n",
    "#classification_report_SVM_gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10708,  5797],\n",
       "       [ 2737, 58595]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ConfusionMatrix_SVM_gridsearch=confusion_matrix(y_test, y_pred_grid_search)\n",
    "#ConfusionMatrix_SVM_gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8903606254095097"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy_score(y_test, y_pred_grid_search) #0.8903606254095097 accuracy of base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization and Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halapets\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...,\n",
       "                                 tokenizer=<function text_data_cleaning at 0x0000017D927C8C18>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "#word vectorization using tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "#create base classifier\n",
    "LR = linear_model.LogisticRegression()\n",
    "\n",
    "#creating a pipeline of steps to be followed for classifier\n",
    "clf_TFIDF_LR = Pipeline([('tfidf', tfidf), ('clf', LR)])#change\n",
    "\n",
    "#fitting model\n",
    "clf_TFIDF_LR.fit(X_train['ReviewUpdated1'], y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model on test data\n",
    "y_pred_TFIDF_LR = clf_TFIDF_LR.predict(X_test['ReviewUpdated1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.81      0.54      0.65      7791\\n     class 1       0.92      0.97      0.94     40227\\n\\n    accuracy                           0.90     48018\\n   macro avg       0.86      0.76      0.80     48018\\nweighted avg       0.90      0.90      0.90     48018\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "ClassificationReport_TFIDF_LR=classification_report(y_test, y_pred_TFIDF_LR, target_names=target_names)\n",
    "ClassificationReport_TFIDF_LR\n",
    "\n",
    "#'              precision    recall  f1-score   support\\n\\n     \n",
    "#class 0       0.81      0.54      0.65      7791\\n     \n",
    "#class 1       0.92      0.97      0.94     40227\\n\\n    \n",
    "#accuracy                          0.90     48018\\n   \n",
    "#macro avg     0.86      0.76      0.80     48018\\n\n",
    "#weighted avg  0.90      0.90      0.90     48018\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4221,  3570],\n",
       "       [ 1018, 39209]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix_TFIDF_LR=confusion_matrix(y_test, y_pred_TFIDF_LR)\n",
    "ConfusionMatrix_TFIDF_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044524969802991"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TFIDF_LR) #0.9044524969802991 accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_LR = pd.DataFrame(y_pred_TFIDF_LR,X_test['Product'])\n",
    "y_pred_TFIDF_LR.rename(columns={0:\"Tags_TFIDF_LR\"}, inplace = True)\n",
    "y_pred_TFIDF_LR.head(5)\n",
    "#len(y_pred_TFIDF_SVM)\n",
    "y_pred_TFIDF_LR.to_csv(\"y_pred_TFIDF_LR.csv\",header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Hyperparameter Search Space \n",
    "# Create regularization penalty space\n",
    "#penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "#C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "#hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 5-fold cross validation\n",
    "#grid_search_LR = GridSearchCV(classifier, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "#grid_search_LR.fit(tfidf.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#best_grid_LR = grid_search_LR.best_estimator_\n",
    "\n",
    "#best_grid_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_grid_search_LR = grid_search_LR.predict(tfidf.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_names = ['class 0', 'class 1']\n",
    "#ClassificationReport_LR_gridsearch=classification_report(y_test, y_pred_grid_search_LR, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConfusionMatrix_LR_gridsearch=confusion_matrix(y_test, y_pred_grid_search_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test, y_pred_grid_search_LR) #0.8903606254095097 accuracy of base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization and Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function text_data_cleaning at 0x0000017D927C8C18>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#word vectorization using tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "#create base classifier\n",
    "NB = BernoulliNB()\n",
    "\n",
    "\n",
    "#creating a pipeline of steps to be followed for classifier\n",
    "clf_TFIDF_NB = Pipeline([('tfidf', tfidf), ('clf', NB)])#change\n",
    "\n",
    "#fitting model\n",
    "clf_TFIDF_NB.fit(X_train['ReviewUpdated1'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model on test data\n",
    "y_pred_TFIDF_NB = clf_TFIDF_NB.predict(X_test['ReviewUpdated1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.72      0.50      0.59      7791\\n     class 1       0.91      0.96      0.93     40227\\n\\n    accuracy                           0.89     48018\\n   macro avg       0.82      0.73      0.76     48018\\nweighted avg       0.88      0.89      0.88     48018\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "ClassificationReport_TFIDF_NB=classification_report(y_test, y_pred_TFIDF_NB, target_names=target_names)\n",
    "ClassificationReport_TFIDF_NB\n",
    "\n",
    "#'              precision    recall  f1-score   support\\n\\n     \n",
    "#class 0       0.72      0.50      0.59      7791\\n     \n",
    "#class 1       0.91      0.96      0.93     40227\\n\\n    \n",
    "#accuracy                          0.89     48018\\n   \n",
    "#macro avg     0.82      0.73      0.76     48018\\n\n",
    "#weighted avg  0.88      0.89      0.88     48018\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3868,  3923],\n",
       "       [ 1487, 38740]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix_TFIDF_NB=confusion_matrix(y_test, y_pred_TFIDF_NB)\n",
    "ConfusionMatrix_TFIDF_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873339164479986"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TFIDF_NB) #0.8873339164479986 accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_NB = pd.DataFrame(y_pred_TFIDF_NB,X_test['Product'])\n",
    "y_pred_TFIDF_NB.rename(columns={0:\"Tags_TFIDF_NB\"}, inplace = True)\n",
    "y_pred_TFIDF_NB.head(5)\n",
    "#len(y_pred_TFIDF_NB)\n",
    "y_pred_TFIDF_NB.to_csv(\"y_pred_TFIDF_NB.csv\",header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization and Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=100,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "#from sklearn.datasets import make_classification\n",
    "#word vectorization using tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "#create base classifier\n",
    "cart = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100) \n",
    "\n",
    "#creating a pipeline of steps to be followed for classifier\n",
    "clf_TFIDF_CART = Pipeline([('tfidf', tfidf), ('clf', cart)])#change\n",
    "\n",
    "#fitting model\n",
    "clf_TFIDF_CART.fit(X_train['ReviewUpdated1'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model on test data\n",
    "y_pred_TFIDF_CART = clf_TFIDF_CART.predict(X_test['ReviewUpdated1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.53      0.49      0.51      7791\\n     class 1       0.90      0.91      0.91     40227\\n\\n    accuracy                           0.85     48018\\n   macro avg       0.71      0.70      0.71     48018\\nweighted avg       0.84      0.85      0.84     48018\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "ClassificationReport_TFIDF_CART=classification_report(y_test, y_pred_TFIDF_CART, target_names=target_names)\n",
    "ClassificationReport_TFIDF_CART\n",
    "\n",
    "#'              precision    recall  f1-score   support\\n\\n     \n",
    "#class 0       0.53      0.49      0.51      7791\\n     \n",
    "#class 1       0.90      0.91      0.91     40227\\n\\n    \n",
    "#accuracy                          0.85     48018\\n   \n",
    "#macro avg     0.71      0.70      0.71     48018\\n\n",
    "#weighted avg  0.84      0.85      0.84     48018\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3795,  3996],\n",
       "       [ 3429, 36798]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix_TFIDF_CART=confusion_matrix(y_test, y_pred_TFIDF_CART)\n",
    "ConfusionMatrix_TFIDF_CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453704860677246"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TFIDF_CART) #0.8453704860677246 accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_CART = pd.DataFrame(y_pred_TFIDF_CART,X_test['Product'])\n",
    "y_pred_TFIDF_CART.rename(columns={0:\"Tags_TFIDF_CART\"}, inplace = True)\n",
    "y_pred_TFIDF_CART.head(5)\n",
    "#len(y_pred_TFIDF_CART)\n",
    "y_pred_TFIDF_CART.to_csv(\"y_pred_TFIDF_CART.csv\",header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_grid = {'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],'max_features': [2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 5-fold cross validation\n",
    "#rf_random  = RandomizedSearchCV(rf, random_grid,n_iter = 100, cv=5, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "#rf_random.fit(tfidf.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#best_grid_RF = rf_random.best_params_\n",
    "\n",
    "#best_grid_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_grid_search_RF = rf_random.predict(tfidf.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_names = ['class 0', 'class 1']\n",
    "#ClassificationReport_RF_gridsearch=classification_report(y_test, y_pred_grid_search_RF, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConfusionMatrix_RF_gridsearch=confusion_matrix(y_test, y_pred_grid_search_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test, y_pred_grid_search_RF) #0.8903606254095097 accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Model based on Individual Classifiers using Majority of voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_NB = pd.read_csv(\"y_pred_TFIDF_NB.csv\",index_col=None)\n",
    "y_pred_TFIDF_LR= pd.read_csv(\"y_pred_TFIDF_LR.csv\",index_col=None)\n",
    "y_pred_TFIDF_CART= pd.read_csv(\"y_pred_TFIDF_CART.csv\",index_col=None)\n",
    "y_pred_TFIDF_SVM= pd.read_csv(\"y_pred_TFIDF_SVM.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_ensb=y_pred_TFIDF_NB.merge(y_pred_TFIDF_LR, how = 'inner',left_index = True, right_index = True, on = 'Product')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_ensb = y_pred_TFIDF_ensb.merge(y_pred_TFIDF_CART, how='inner', left_index = True, right_index = True, on = 'Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48018, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_TFIDF_ensb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Tags_TFIDF_NB</th>\n",
       "      <th>Tags_TFIDF_LR</th>\n",
       "      <th>Tags_TFIDF_CART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xiaomi Redmi 4A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo K3 Note</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy Note 3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi Redmi Note 3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xiaomi Redmi 3S Prime</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Product  Tags_TFIDF_NB  Tags_TFIDF_LR  Tags_TFIDF_CART\n",
       "0        Xiaomi Redmi 4A              1              1                1\n",
       "1         Lenovo K3 Note              1              1                0\n",
       "2  Samsung Galaxy Note 3              1              1                1\n",
       "3    Xiaomi Redmi Note 3              1              1                1\n",
       "4  Xiaomi Redmi 3S Prime              1              1                1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_TFIDF_ensb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_ensb = y_pred_TFIDF_ensb.merge(y_pred_TFIDF_SVM, how='inner', left_index = True, right_index = True, on = 'Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product', 'Tags_TFIDF_NB', 'Tags_TFIDF_LR', 'Tags_TFIDF_CART',\n",
       "       'Tags_TFIDF_SVM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_TFIDF_ensb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding weights on classifiers based on the performance of the classifiers in terms of accuracy, precision and recall\n",
    "#Naive Bayes and Decision Tree has been added a weight of 0.5 each\n",
    "y_pred_TFIDF_ensb[\"Total Votes\"] = (0.5*y_pred_TFIDF_ensb[\"Tags_TFIDF_NB\"])+y_pred_TFIDF_ensb[\"Tags_TFIDF_LR\"] + (0.5*y_pred_TFIDF_ensb[\"Tags_TFIDF_CART\"])+y_pred_TFIDF_ensb[\"Tags_TFIDF_SVM\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TFIDF_ensb[\"Majority of Votes\"]  = [1 if x >=2 else 0 for x in y_pred_TFIDF_ensb[\"Total Votes\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n     class 0       0.79      0.57      0.66      7791\\n     class 1       0.92      0.97      0.95     40227\\n\\n    accuracy                           0.91     48018\\n   macro avg       0.85      0.77      0.80     48018\\nweighted avg       0.90      0.91      0.90     48018\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "ClassificationReport_TFIDF_Ensemble=classification_report(y_test, y_pred_TFIDF_ensb[\"Majority of Votes\"], target_names=target_names)\n",
    "ClassificationReport_TFIDF_Ensemble\n",
    "\n",
    "#'              precision    recall  f1-score   support\\n\\n     \n",
    "#class 0       0.79      0.57      0.66      7791\\n     \n",
    "#class 1       0.92      0.97      0.95     40227\\n\\n    \n",
    "#accuracy                          0.91     48018\\n   \n",
    "#macro avg     0.85      0.77      0.80     48018\\n\n",
    "#weighted avg  0.90      0.91      0.90     48018\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4467,  3324],\n",
       "       [ 1206, 39021]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix_TFIDF_Ensemble=confusion_matrix(y_test, y_pred_TFIDF_ensb[\"Majority of Votes\"])\n",
    "ConfusionMatrix_TFIDF_Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056603773584906"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TFIDF_ensb[\"Majority of Votes\"]) #0.9056603773584906 accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
